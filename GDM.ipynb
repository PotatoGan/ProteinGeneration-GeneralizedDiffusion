{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deblurring_diffusion_pytorch import Unet, GaussianDiffusion, Trainer, ProteinDataset2ESM, ProteinDataset\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import errno\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data.csv')\n",
    "\n",
    "df1.info()\n",
    "use_df = df1[:]\n",
    "use_df.head(10)\n",
    "feature = df1['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[df1['feature'].str.len().between(15, inputSize)]\n",
    "print('一共有{}条数据'.format(len(df2)))\n",
    "print(df2.head())\n",
    "feature = df2['feature'].tolist()\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=1\n",
    ").cuda()\n",
    "\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = inputSize,\n",
    "    device_of_kernel = 'cuda',\n",
    "    channels = 1,\n",
    "    timesteps = 20,\n",
    "    loss_type = 'l1',\n",
    "    kernel_std=0.1,\n",
    "    kernel_size=3,\n",
    "    blur_routine='Incremental',\n",
    "    train_routine = 'Final',\n",
    "    sampling_routine = 'x0_step_down',\n",
    "    discrete=False,\n",
    "    results_folder = './tmp/4',\n",
    "    indices_to_skip = []\n",
    ").cuda()\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    feature,\n",
    "    image_size = inputSize,\n",
    "    train_batch_size = 5,\n",
    "    train_lr = 2e-5,\n",
    "    train_num_steps = 501,\n",
    "    gradient_accumulate_every = 2,\n",
    "    ema_decay = 0.995, \n",
    "    fp16 = False, \n",
    "    results_folder = './tmp/4',\n",
    "    dataset = 'Protein'\n",
    ")\n",
    "\n",
    "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testProtein = ['ADNKFNKEQQNAFYEILHLPNLNEEQRNGFIQSLKDDPSQSANLLAEAKKLNDAQAPK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def new_method(self):\n",
    "    print(\"This is a new method\")\n",
    "\n",
    "tester =Trainer(\n",
    "    diffusion,\n",
    "    #'./root_mnist',\n",
    "    testProtein,\n",
    "    image_size = inputSize,\n",
    "    train_batch_size = 1,\n",
    "    train_lr = 2e-5,\n",
    "    train_num_steps = 1001,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    fp16 = False,                       # turn on mixed precision training with apex\n",
    "    results_folder = './tmp/6',\n",
    "    dataset = 'Protein',\n",
    "    load_path = './tmp/4/model_500.pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogProtein, noiseProtein, deNoiseProtein = tester.test_from_data('test', d_times = 20, s_times= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_onehot(matrix):\n",
    "    max_values = np.max(matrix[:,:,:,:21], axis=-1, keepdims=True)  \n",
    "    onehot_matrix = np.where(matrix == max_values, 1, 0)\n",
    "    return onehot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_protein(onehot_tensor):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "    num_rows, num_cols = onehot_tensor.shape\n",
    "    protein_sequence = []\n",
    "    for i in range(num_rows):\n",
    "        max_index = np.argmax(onehot_tensor[i])\n",
    "        protein_sequence.append(amino_acids[max_index])\n",
    "    \n",
    "    return ''.join(protein_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_tensor = normalize_onehot(deNoiseProtein[19].cpu().numpy()).squeeze()\n",
    "protein_sequence = onehot_to_protein(onehot_tensor)\n",
    "print(protein_sequence[:58])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
